{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.5.0\n"
     ]
    }
   ],
   "source": [
    "# https://colab.research.google.com/github/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world/train/train_hello_world_model.ipynb#scrollTo=aCZBFzjClURz\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "if tf.__version__ != '2.5.0': \n",
    "    print('Needs to run on tf 2.5.0!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('../data/labelled_data/prepared-samples-binary.json')\n",
    "\n",
    "y = df['label'].to_numpy()\n",
    "X = np.array(df['data'].to_list())\n",
    "X = np.expand_dims(X, axis=3)\n",
    "print(y.shape)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train / val / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for experiment reproducibility\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to model files\n",
    "MODELS_DIR = 'models/'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_TF = MODELS_DIR + 'squeezenet-binary'\n",
    "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'squeezenet-binary_no_quant.tflite'\n",
    "MODEL_TFLITE = MODELS_DIR + 'squeezenet-binary.tflite'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "model_no_quant_tflite = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "494608"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Convert the model to the TensorFlow Lite format with quantization\n",
    "def representative_dataset():\n",
    "  for i in range(50):\n",
    "    # for CNN the input is NOT flattened\n",
    "    yield([X_train[i].reshape(1, 32, 32, 1).astype(np.float32)])\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "model_tflite = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160696"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate size\n",
    "# careful - this does not count everything properly\n",
    "# size_tf = os.path.getsize(MODEL_TF)\n",
    "# better version:\n",
    "from pathlib import Path\n",
    "root_directory = Path(MODEL_TF)\n",
    "size_tf = sum(f.stat().st_size for f in root_directory.glob('**/*') if f.is_file())\n",
    "\n",
    "size_no_quant_tflite = os.path.getsize(MODEL_NO_QUANT_TFLITE)\n",
    "size_tflite = os.path.getsize(MODEL_TFLITE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    Size                            \n",
      "Model                                                               \n",
      "TensorFlow                 2996689 bytes                            \n",
      "TensorFlow Lite            494608 bytes   (reduced by 2502081 bytes)\n",
      "TensorFlow Lite Quantized   160696 bytes   (reduced by 333912 bytes)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compare size\n",
    "size_comparison = pd.DataFrame.from_records(\n",
    "  [[\"TensorFlow\", f\"{size_tf} bytes\", \"\"],\n",
    "    [\"TensorFlow Lite\", f\"{size_no_quant_tflite} bytes \", f\"(reduced by {size_tf - size_no_quant_tflite} bytes)\"],\n",
    "    [\"TensorFlow Lite Quantized\", f\"{size_tflite} bytes\", f\"(reduced by {size_no_quant_tflite - size_tflite} bytes)\"]],\n",
    "    columns = [\"Model\", \"Size\", \"\"], index=\"Model\")\n",
    "\n",
    "print(size_comparison)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dd871d7f70946c202e88909d823f091c0fd6059bd1e3c41716b5836c6cdfc103"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('tf25': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
